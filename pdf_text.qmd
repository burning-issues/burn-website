---
title: "Text Analysis of a Research Article"
author: "Francisco J. Guerrero"
---

A quick text analysis of: [Wildfires increasingly impact western US fluvial networks](https://www.nature.com/articles/s41467-021-22747-3) by Ball et al., 2021.

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# A Text analysis with [Tidytext](https://www.tidytextmining.com/index.html)

This is an exploratory data analysis (flesh out later)

```{r echo = FALSE, warning=FALSE, message=FALSE}


require(librarian)
librarian::shelf(dplyr, tidytext, tidyverse,
                 widyr,igraph, ggraph,
                 wordcloud, reshape2, graphlayouts,
                 pluralize, quanteda, qgraph, cowplot, readr, pdftools)
```

## Downloading the paper

```{r}
# download.file("https://www.nature.com/articles/s41467-021-22747-3.pdf","assets/wq_burning.pdf", mode = "wb")
ppr <- pdf_text("assets/wq_burning.pdf")
#You may need to disconnect the VPN for this line to work
```

## Checking the files
```{r}
length(ppr)
# cat(ppr[2:6])# Body of the paper excluding literature cited
typeof(ppr)#This shows that the file is already a vector (most likely a result of using pdftools)
```

## Cleaning the pdf file
```{r}
ppr_cln <- pdftools::pdf_text(pdf = ppr) %>% 
  str_to_lower() #%>%
  # str_replace_all("\\t","") %>% 
  # str_replace_all("\n"," ") %>% 
  # str_replace_all("     "," ") %>% 
  # str_replace_all("    "," ") %>%
  # str_replace_all("   "," ") %>% 
  # str_replace_all("  "," ") %>% 
  # str_replace_all("[:digit;]", " ") %>% 
  # str_replace_all("[:punct:]", " ") %>% 
  # str_trim()
```



## Converting the file into a dataframe for text analysis
```{r}
ppr_txt <- data.frame(line = 1:8, text = ppr)
```


```




### Converting the pdf text into tokens / a token is a word in prose text
```{r}
ppr_tokens <- ppr_txt %>% 
  unnest_tokens(output = word, input = text)
```

### Removing stop words
```{r}
tidy_ppr <- ppr_tokens %>% 
  anti_join(stop_words, by = "word") %>% 
  filter(str_detect(word,"[:alpha:]")) %>% 
  filter(!word%in%c("article","communications","doi.org","https","nature","naturecommunications","s41467",
                    "www.nature.com","slba","fig")) %>% 
  count(word, sort = TRUE) %>% 
  mutate(length = nchar(word)) %>% 
  select(word, n) %>% 
  mutate(rank = row_number(),
         total=sum(n),
         t_freq = n/total)
```

### Creating a word-cloud
```{r}
tidy_ppr %>% with(wordcloud(word,n,max.words = 400, scale = c(3.5,0.35)))
```


```{r}
#Distribution of frequency values
tidy_ppr %>% filter(rank<40) %>% 
  ggplot(aes(t_freq, fct_reorder(word, t_freq), fill = t_freq)) +
  geom_col(show.legend = FALSE) +
  labs(x = "Frequency", y = NULL)

#Zipf's law for survey answers
tidy_ppr %>% 
  ggplot(aes(rank,t_freq)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  geom_abline(intercept = -0.62, slope = -1.1, 
              color = "gray50", linetype = 2) +
  scale_x_log10() +
  scale_y_log10()
```
```{r}
ppr_digrams <- ppr_txt %>%
  filter(!word%in%c("article","communications","doi.org","https","nature","naturecommunications","s41467",
                    "www.nature.com","slba","fig")) %>% 
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>% 
  separate(bigram,c("word1", "word2"), sep = " ") %>% 
  filter(!word1 %in% stop_words$word) %>% 
  filter(!word2 %in% stop_words$word) %>% 
  count(word1, word2, sort = TRUE) %>% 
  mutate(rank = row_number(),
         total=sum(n),
         t_freq = n/total)
head(ppr_digrams)

# #Distribution of frequency values
# pq_digrams %>% filter(rank < 26) %>% 
#   unite(bigram, word1, word2, sep = " ") %>% 
#   ggplot(aes(t_freq, fct_reorder(bigram, t_freq), fill = t_freq)) +
#   geom_col(show.legend = FALSE) +
#   labs(x = "Frequency", y = NULL)
# 
# #Zipf's law for survey answers
# pq_digrams %>% 
#   ggplot(aes(rank,t_freq)) + 
#   geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
#   geom_abline(intercept = -0.62, slope = -1.1, 
#               color = "gray50", linetype = 2) +
#   scale_x_log10() +
#   scale_y_log10()+
#   xlab("Rarity")+
#   ylab("Frequency")
```




```{r}
bigram_graph <- pq_digrams %>%
  filter(rank < 101) %>%
  graph_from_data_frame()
bigram_graph

set.seed(2017)


l <- layout_with_fr(bigram_graph)
e <- get.edgelist(bigram_graph,names=FALSE)
m <- qgraph.layout.fruchtermanreingold(e,vcount=vcount(bigram_graph))
deg <- degree(bigram_graph,mode="all")
fsize <- degree(bigram_graph, mode= "all")

#png(filename=paste("assets/NetworkAnalysis_words_",Sys.Date(),".png", sep = ""), res = 100)

plot(bigram_graph,layout=m, edge.arrow.size =.05,vertex.color = "pink", vertex.size =500,vertex.frame.color="deeppink",vertex.label.color="black", vertex.label.cex=fsize/5,vertex.label.dist=0.8,edge.curve = 0.75,edge.color="skyblue",edge.label.family="Arial", rescale=F, axes = FALSE, ylim = c(-50,90), xlim = c(-55,120), asp =0)

#dev.off()

#png(filename=paste("assets/NetworkAnalysis_bubbles_",Sys.Date(),".png", sep = ""), res = 100)

plot(bigram_graph,layout=m, edge.arrow.size =.05,vertex.color = "pink", vertex.size =deg*150,vertex.frame.color="deeppink",vertex.label.color="black", vertex.label.cex=0.55,vertex.label.dist=0.8,edge.curve = 0.75,edge.color="skyblue",edge.label.family="Arial", rescale=F, axes = FALSE, ylim = c(-50,90), xlim = c(-55,120), asp =0)

#dev.off()

```





























