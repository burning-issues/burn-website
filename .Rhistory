ppr_txt0 <- unlist(ppr)
ppr_txt <- data.frame(line = 1:8, text = ppr_txt0)
sbj <- unlist(strsplit(info$keys$Subject, " "))
dmn <- unlist(strsplit(info$keys$`CrossMarkDomains[1]`," "))
ctr <- unlist(strsplit(info$keys$Creator, " "))
doi <- info$keys$doi
cdm <- info$keys$`CrossMarkDomains[2]`
ppr_txt$text <- sub(paste(sbj, collapse = '|'),'',ppr_txt)
ppr_txt$text <- sub(paste(dmn, collapse = '|'),'',ppr_txt)
ppr_txt$text <- sub(paste(ctr, collapse = '|'),'',ppr_txt)
ppr_cln <- ppr_txt%>%
unnest_tokens(output = word, input = text) %>%
anti_join(stop_words, by = "word") %>%
filter(str_detect(word,"[:alpha:]")) %>%
count(word, sort = TRUE) %>%
mutate(length = nchar(word)) %>%
select(word, n) %>%
mutate(rank = row_number(),
total=sum(n),
t_freq = n/total)
ppr_cln %>% with(wordcloud(word,n,max.words = 400))
knitr::opts_chunk$set(echo = TRUE)
#library(dplyr)
#library(tidytext)
#library(tidyverse)
#library(widyr)
#library(igraph)
#library(ggraph)
#library(wordcloud)
#library(reshape2)
#library(graphlayouts)
#library(pluralize)
#library(quanteda)
# library(spacyr)
# library(reticulate)
#library(igraph)
#library(graphlayouts)
#library(qgraph)
# require(pacman)
# pacman::p_load(dplyr, tidytext, tidyverse,
#             widyr,igraph, ggraph,
#             wordcloud, reshape2, graphlayouts,
#             pluralize, quanteda, qgraph, cowplot, readr)
require(librarian)
librarian::shelf(plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
#Function to adjust table width:
html_table_width <- function(kable_output, width){
width_html <- paste0(paste0('<col width="', width, '">'), collapse = "\n")
sub("<table>", paste0("<table>\n", width_html), kable_output)
}
# Source: https://github.com/rstudio/bookdown/issues/122
knitr::opts_chunk$set(echo = TRUE)
require(librarian)
librarian::shelf(plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
#Function to adjust table width:
html_table_width <- function(kable_output, width){
width_html <- paste0(paste0('<col width="', width, '">'), collapse = "\n")
sub("<table>", paste0("<table>\n", width_html), kable_output)
}
# Source: https://github.com/rstudio/bookdown/issues/122
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
glimpse(abs_df)
#
# t_df1 <- as.data.frame(rbind(t_df[c(1:3),],t_df[c(68:71),], row.names = FALSE))
# colnames(t_df1) <- c("ID", "Question type", "Answers")
# knitr::kable(head(t_df1),format="html")%>%
#    html_table_width(c(100,100,500))
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
glimpse(abs_df)
abs_df1 <- dplyr:select(abs_df,Key,Author,Title,Journal,`Abstract Note`)
require(librarian)
librarian::shelf(dplyr, plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
#Function to adjust table width:
html_table_width <- function(kable_output, width){
width_html <- paste0(paste0('<col width="', width, '">'), collapse = "\n")
sub("<table>", paste0("<table>\n", width_html), kable_output)
}
# Source: https://github.com/rstudio/bookdown/issues/122
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
glimpse(abs_df)
abs_df1 <- dplyr:select(abs_df,Key,Author,Title,Journal,`Abstract Note`)
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
glimpse(abs_df)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,Journal,`Abstract Note`)
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
glimpse(abs_df)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
#
# t_df1 <- as.data.frame(rbind(t_df[c(1:3),],t_df[c(68:71),], row.names = FALSE))
# colnames(t_df1) <- c("ID", "Question type", "Answers")
# knitr::kable(head(t_df1),format="html")%>%
#    html_table_width(c(100,100,500))
glimpse(abs_df1)
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
glimpse(abs_df)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
abs_df1 <- rename(abs_df1,
id = key,
author = Author,
title = Title,
journal = `Publication Title`,
abstract = `Abstract Note)
#
# t_df1 <- as.data.frame(rbind(t_df[c(1:3),],t_df[c(68:71),], row.names = FALSE))
# colnames(t_df1) <- c("ID", "Question type", "Answers")
# knitr::kable(head(t_df1),format="html")%>%
#    html_table_width(c(100,100,500))
glimpse(abs_df1)
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
glimpse(abs_df)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
abs_df1 <- rename(abs_df1,
id = key,
author = Author,
title = Title,
journal = `Publication Title`,
abstract = `Abstract Note`)
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
glimpse(abs_df)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
abs_df1 <- rename(abs_df1,
id = key,
author = Author,
title = Title,
journal = `Publication Title`,
abstract = `Abstract Note`)
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
glimpse(abs_df)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
abs_df1 <- rename(abs_df1,
id = Key,
author = Author,
title = Title,
journal = `Publication Title`,
abstract = `Abstract Note`)
#
# t_df1 <- as.data.frame(rbind(t_df[c(1:3),],t_df[c(68:71),], row.names = FALSE))
# colnames(t_df1) <- c("ID", "Question type", "Answers")
# knitr::kable(head(t_df1),format="html")%>%
#    html_table_width(c(100,100,500))
glimpse(abs_df1)
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
abs_df1 <- rename(abs_df1,
id = Key,
author = Author,
title = Title,
journal = `Publication Title`,
abstract = `Abstract Note`)
abs_df1%>%
unnest_tokens(output = word, input = title)%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n, scale = c(3, .07)))
abs_df1%>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n, scale = c(3, .07)))
abs_df1$title
abs_df1%>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n))#, scale = c(3, .07)
unnest_tokens(output = word, input = title)
abs_df1%>%
unnest_tokens(output = word, input = title)
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n))#, scale = c(3, .07)
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct()
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n,scale = c(1.5, .07)))#,
?wordcloud
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n,scale = c(3, .05)))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n,scale = c(3, .05),max.words = Inf))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n,scale = c(3, .05),max.words = Inf,min.freq=1))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n,scale = c(4, .05),max.words = Inf,min.freq=1))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n,scale = c(4, .05),max.words = Inf,min.freq=2))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
filter(word!=fire) %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
filter(word!="fire") %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
filter(word!="fire" | word!="wildfire") %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
filter(word!="fire") %>%
filter(word!= "Wildfire") %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
filter(word!="fire") %>%
filter(word!= "Wildfire") %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
# filter(word!="fire") %>%
# filter(word!= "Wildfire") %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
# filter(word!="fire") %>%
# filter(word!= "Wildfire") %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))
knitr::opts_chunk$set(echo = TRUE)
require(librarian)
librarian::shelf(dplyr, plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
#Function to adjust table width:
html_table_width <- function(kable_output, width){
width_html <- paste0(paste0('<col width="', width, '">'), collapse = "\n")
sub("<table>", paste0("<table>\n", width_html), kable_output)
}
# Source: https://github.com/rstudio/bookdown/issues/122
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
abs_df1 <- rename(abs_df1,
id = Key,
author = Author,
title = Title,
journal = `Publication Title`,
abstract = `Abstract Note`)
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
abs_df1 <- rename(abs_df1,
id = Key,
author = Author,
title = Title,
journal = `Publication Title`,
abstract = `Abstract Note`)
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
# filter(word!="fire") %>%
# filter(word!= "Wildfire") %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
abs_df1
glimpse(abs_df1)
abs_df1 <- rename(abs_df1,
id = Key,
author = Author,
title = Title,
journal = `Publication Title`,
abstract = `Abstract Note`)
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
abs_df1 <- rename(abs_df1,
id = Key,
author = Author,
title = Title,
journal = `Publication Title`,
abstract = `Abstract Note`)
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = TRUE)
glimpse(abs_df)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
abs_df1 <- rename(abs_df1,
id = Key,
author = Author,
title = Title,
journal = `Publication Title`,
abstract = `Abstract Note`)
knitr::opts_chunk$set(echo = TRUE)
require(librarian)
librarian::shelf(dplyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr,spacyr)
spacy_install()
knitr::opts_chunk$set(echo = TRUE)
require(librarian)
librarian::shelf(plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
#Function to adjust table width:
html_table_width <- function(kable_output, width){
width_html <- paste0(paste0('<col width="', width, '">'), collapse = "\n")
sub("<table>", paste0("<table>\n", width_html), kable_output)
}
# Source: https://github.com/rstudio/bookdown/issues/122
pluralize("tests")
singularize("tests")
#For research area questions
ra_dat <- t_df%>%filter(question=="research-a")
#For pressing questions
pq_dat <- t_df%>%filter(question=="pressing-q")
ra_dat%>%
unnest_tokens(output = word, input = answers)%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n, scale = c(3, .07)))
stp_eg <- as.data.frame(rbind(head(stop_words),
tail(stop_words)),
row.names = FALSE)
colnames(stp_eg) <- c("Stop word", "Lexicon")
knitr::kable(stp_eg,format="html") %>%
html_table_width(c(200,200))
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(pq_tokens)
pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
distinct() %>%
count(word, sort = TRUE) %>%
with(wordcloud(word,n, scale = c(4, .1)))
pq_dat
pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
distinct() %>%
singularize(word) %>%
count(word, sort = TRUE) %>%
with(wordcloud(word,n, scale = c(4, .1)))
pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
distinct() %>%
singularize() %>%
count(word, sort = TRUE) %>%
with(wordcloud(word,n, scale = c(4, .1)))
require(librarian)
librarian::shelf(plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
#Function to adjust table width:
html_table_width <- function(kable_output, width){
width_html <- paste0(paste0('<col width="', width, '">'), collapse = "\n")
sub("<table>", paste0("<table>\n", width_html), kable_output)
}
# Source: https://github.com/rstudio/bookdown/issues/122
t_df <- read_csv("assets/data/wildfires-survey-answers_formatted.csv",show_col_types = FALSE)
t_df1 <- as.data.frame(rbind(t_df[c(1:3),],t_df[c(68:71),], row.names = FALSE))
colnames(t_df1) <- c("ID", "Question type", "Answers")
knitr::kable(head(t_df1),format="html")%>%
html_table_width(c(100,100,500))
#For research area questions
ra_dat <- t_df%>%filter(question=="research-a")
#For pressing questions
pq_dat <- t_df%>%filter(question=="pressing-q")
head(pq_tokens)
x <- pq_tokens$word
singularize(x)
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
singularize() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
singularize(word) %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
?singularize()
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
singularize(pq_tokens$word) %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
rowwise() %>% mutate(singular = singularize(word)) %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(pq_tokens)
pq_tokens
print(n = 120)
print(pq_tokens, n = 120)
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(pq_tokens)
pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
distinct() %>%
rowwise() %>% mutate(word = singularize(word)) %>%
count(word, sort = TRUE) %>%
with(wordcloud(word,n, scale = c(4, .1)))
pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
distinct() %>%
# rowwise() %>% mutate(word = singularize(word)) %>%
count(word, sort = TRUE) %>%
with(wordcloud(word,n, scale = c(4, .1)))
