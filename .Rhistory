filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct()
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n,scale = c(1.5, .07)))#,
?wordcloud
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n,scale = c(3, .05)))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n,scale = c(3, .05),max.words = Inf))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n,scale = c(3, .05),max.words = Inf,min.freq=1))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n,scale = c(4, .05),max.words = Inf,min.freq=1))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n,scale = c(4, .05),max.words = Inf,min.freq=2))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
filter(word!=fire) %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
filter(word!="fire") %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))#,
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
filter(word!="fire" | word!="wildfire") %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
filter(word!="fire") %>%
filter(word!= "Wildfire") %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
filter(word!="fire") %>%
filter(word!= "Wildfire") %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
# filter(word!="fire") %>%
# filter(word!= "Wildfire") %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
# filter(word!="fire") %>%
# filter(word!= "Wildfire") %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))
knitr::opts_chunk$set(echo = TRUE)
require(librarian)
librarian::shelf(dplyr, plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
#Function to adjust table width:
html_table_width <- function(kable_output, width){
width_html <- paste0(paste0('<col width="', width, '">'), collapse = "\n")
sub("<table>", paste0("<table>\n", width_html), kable_output)
}
# Source: https://github.com/rstudio/bookdown/issues/122
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
abs_df1 <- rename(abs_df1,
id = Key,
author = Author,
title = Title,
journal = `Publication Title`,
abstract = `Abstract Note`)
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
abs_df1 <- rename(abs_df1,
id = Key,
author = Author,
title = Title,
journal = `Publication Title`,
abstract = `Abstract Note`)
abs_df1%>% select(id,title) %>%
unnest_tokens(output = word, input = title)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
count(word, sort = TRUE)%>%
distinct() %>%
# filter(word!="fire") %>%
# filter(word!= "Wildfire") %>%
with(wordcloud(word,n,scale = c(4, .07),max.words = Inf,min.freq=1))
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
abs_df1
glimpse(abs_df1)
abs_df1 <- rename(abs_df1,
id = Key,
author = Author,
title = Title,
journal = `Publication Title`,
abstract = `Abstract Note`)
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = FALSE)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
abs_df1 <- rename(abs_df1,
id = Key,
author = Author,
title = Title,
journal = `Publication Title`,
abstract = `Abstract Note`)
abs_df <- read_csv("assets/data/fire_science_future.csv",show_col_types = TRUE)
glimpse(abs_df)
abs_df1 <- dplyr::select(abs_df,Key,Author,Title,`Publication Title`,`Abstract Note`)
abs_df1 <- rename(abs_df1,
id = Key,
author = Author,
title = Title,
journal = `Publication Title`,
abstract = `Abstract Note`)
knitr::opts_chunk$set(echo = TRUE)
require(librarian)
librarian::shelf(dplyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr,spacyr)
spacy_install()
knitr::opts_chunk$set(echo = TRUE)
require(librarian)
librarian::shelf(plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
#Function to adjust table width:
html_table_width <- function(kable_output, width){
width_html <- paste0(paste0('<col width="', width, '">'), collapse = "\n")
sub("<table>", paste0("<table>\n", width_html), kable_output)
}
# Source: https://github.com/rstudio/bookdown/issues/122
pluralize("tests")
singularize("tests")
#For research area questions
ra_dat <- t_df%>%filter(question=="research-a")
#For pressing questions
pq_dat <- t_df%>%filter(question=="pressing-q")
ra_dat%>%
unnest_tokens(output = word, input = answers)%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n, scale = c(3, .07)))
stp_eg <- as.data.frame(rbind(head(stop_words),
tail(stop_words)),
row.names = FALSE)
colnames(stp_eg) <- c("Stop word", "Lexicon")
knitr::kable(stp_eg,format="html") %>%
html_table_width(c(200,200))
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(pq_tokens)
pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
distinct() %>%
count(word, sort = TRUE) %>%
with(wordcloud(word,n, scale = c(4, .1)))
pq_dat
pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
distinct() %>%
singularize(word) %>%
count(word, sort = TRUE) %>%
with(wordcloud(word,n, scale = c(4, .1)))
pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
distinct() %>%
singularize() %>%
count(word, sort = TRUE) %>%
with(wordcloud(word,n, scale = c(4, .1)))
require(librarian)
librarian::shelf(plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
#Function to adjust table width:
html_table_width <- function(kable_output, width){
width_html <- paste0(paste0('<col width="', width, '">'), collapse = "\n")
sub("<table>", paste0("<table>\n", width_html), kable_output)
}
# Source: https://github.com/rstudio/bookdown/issues/122
t_df <- read_csv("assets/data/wildfires-survey-answers_formatted.csv",show_col_types = FALSE)
t_df1 <- as.data.frame(rbind(t_df[c(1:3),],t_df[c(68:71),], row.names = FALSE))
colnames(t_df1) <- c("ID", "Question type", "Answers")
knitr::kable(head(t_df1),format="html")%>%
html_table_width(c(100,100,500))
#For research area questions
ra_dat <- t_df%>%filter(question=="research-a")
#For pressing questions
pq_dat <- t_df%>%filter(question=="pressing-q")
head(pq_tokens)
x <- pq_tokens$word
singularize(x)
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
singularize() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
singularize(word) %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
?singularize()
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
singularize(pq_tokens$word) %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
rowwise() %>% mutate(singular = singularize(word)) %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(pq_tokens)
pq_tokens
print(n = 120)
print(pq_tokens, n = 120)
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(pq_tokens)
pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
distinct() %>%
rowwise() %>% mutate(word = singularize(word)) %>%
count(word, sort = TRUE) %>%
with(wordcloud(word,n, scale = c(4, .1)))
pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
distinct() %>%
# rowwise() %>% mutate(word = singularize(word)) %>%
count(word, sort = TRUE) %>%
with(wordcloud(word,n, scale = c(4, .1)))
require(librarian)
librarian::shelf(plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
t_df <- read_csv("assets/data/wildfires_survey_all_answers.csv",show_col_types = FALSE)
require(librarian)
librarian::shelf(plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
t_df <- read_csv("assets/data/wildfires_survey_all_answers.csv",show_col_types = FALSE)
t_df
t_df%>%
unnest_tokens(output = word, input = answers)%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n, scale = c(3, .07)))
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
count(word, sort = FALSE) %>%
rowwise() %>% mutate(word = singularize(word)) %>%
mutate(length = nchar(word))
head(aq_tokens)
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
count(word, sort = FALSE) %>%
rowwise() %>% mutate(word = singularize(word)) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .1)))
?distinct()
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
count(word, sort = FALSE) %>%
rowwise() %>% mutate(word = singularize(word)) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .1)))
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = singularize(word)) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .1)))
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(ifelse(word=!"data",word = singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .1)))
?ifelse()
?if_else()
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(if_else(word=!"data",word = singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .1)))
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = singularize(word)) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .1)))
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .1)))
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .05)))
# head(aq_tokens)
?unnest_tokens()
head(t_df)
tail(t_df)
head(t_df)
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .05)))
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(aq_tokens)
t_df <- as.tibble(read_csv("assets/data/wildfires_survey_all_answers.csv",show_col_types = FALSE))
t_df <- as_tibble(read_csv("assets/data/wildfires_survey_all_answers.csv",show_col_types = FALSE))
t_df
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
?unnest_tokens90
?unnest_tokens()
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers, drop = FALSE)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(aq_tokens)
aq_tokens <- t_df %>%
ungroup() %>%
unnest_tokens(output = word, input = answers, drop = FALSE)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(aq_tokens)
aq_tokens1 <- t_df %>%
select(everything()) %>%
mutate(text = unnest_tokens(output = word, input = answers, drop = FALSE)) %>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(text,"[:alpha:]"))%>%
rowwise() %>% mutate(text = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(text, sort = FALSE) %>%
mutate(length = nchar(text))
aq_tokens1 <- t_df %>%
select(everything()) %>%
ungroup() %>%
mutate(text = unnest_tokens(output = word, input = answers, drop = FALSE)) %>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(text,"[:alpha:]"))%>%
rowwise() %>% mutate(text = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(text, sort = FALSE) %>%
mutate(length = nchar(text))
knitr::opts_chunk$set(echo = TRUE)
require(librarian)
librarian::shelf(plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
#Function to adjust table width:
html_table_width <- function(kable_output, width){
width_html <- paste0(paste0('<col width="', width, '">'), collapse = "\n")
sub("<table>", paste0("<table>\n", width_html), kable_output)
}
# Source: https://github.com/rstudio/bookdown/issues/122
t_df <- read_csv("assets/data/wildfires-survey-answers_formatted.csv",show_col_types = FALSE)
t_df1 <- as.data.frame(rbind(t_df[c(1:3),],t_df[c(68:71),], row.names = FALSE))
colnames(t_df1) <- c("ID", "Question type", "Answers")
knitr::kable(head(t_df1),format="html")%>%
html_table_width(c(100,100,500))
