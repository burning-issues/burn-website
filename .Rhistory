pluralize, quanteda, qgraph, cowplot, readr)
#Function to adjust table width:
html_table_width <- function(kable_output, width){
width_html <- paste0(paste0('<col width="', width, '">'), collapse = "\n")
sub("<table>", paste0("<table>\n", width_html), kable_output)
}
# Source: https://github.com/rstudio/bookdown/issues/122
t_df <- read_csv("assets/data/wildfires-survey-answers_formatted.csv",show_col_types = FALSE)
t_df1 <- as.data.frame(rbind(t_df[c(1:3),],t_df[c(68:71),], row.names = FALSE))
colnames(t_df1) <- c("ID", "Question type", "Answers")
knitr::kable(head(t_df1),format="html")%>%
html_table_width(c(100,100,500))
#For research area questions
ra_dat <- t_df%>%filter(question=="research-a")
#For pressing questions
pq_dat <- t_df%>%filter(question=="pressing-q")
head(pq_tokens)
x <- pq_tokens$word
singularize(x)
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
singularize() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
singularize(word) %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
?singularize()
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
singularize(pq_tokens$word) %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
rowwise() %>% mutate(singular = singularize(word)) %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(pq_tokens)
pq_tokens
print(n = 120)
print(pq_tokens, n = 120)
pq_tokens <- pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(pq_tokens)
pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
distinct() %>%
rowwise() %>% mutate(word = singularize(word)) %>%
count(word, sort = TRUE) %>%
with(wordcloud(word,n, scale = c(4, .1)))
pq_dat %>%
unnest_tokens(output = word, input = answers)%>%
distinct() %>%
# rowwise() %>% mutate(word = singularize(word)) %>%
count(word, sort = TRUE) %>%
with(wordcloud(word,n, scale = c(4, .1)))
require(librarian)
librarian::shelf(plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
t_df <- read_csv("assets/data/wildfires_survey_all_answers.csv",show_col_types = FALSE)
require(librarian)
librarian::shelf(plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
t_df <- read_csv("assets/data/wildfires_survey_all_answers.csv",show_col_types = FALSE)
t_df
t_df%>%
unnest_tokens(output = word, input = answers)%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n, scale = c(3, .07)))
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
count(word, sort = FALSE) %>%
rowwise() %>% mutate(word = singularize(word)) %>%
mutate(length = nchar(word))
head(aq_tokens)
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
count(word, sort = FALSE) %>%
rowwise() %>% mutate(word = singularize(word)) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .1)))
?distinct()
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
distinct() %>%
count(word, sort = FALSE) %>%
rowwise() %>% mutate(word = singularize(word)) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .1)))
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = singularize(word)) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .1)))
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(ifelse(word=!"data",word = singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .1)))
?ifelse()
?if_else()
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(if_else(word=!"data",word = singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .1)))
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = singularize(word)) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .1)))
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .1)))
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .05)))
# head(aq_tokens)
?unnest_tokens()
head(t_df)
tail(t_df)
head(t_df)
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word)) %>%
with(wordcloud(word,n, scale = c(4, .05)))
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(aq_tokens)
t_df <- as.tibble(read_csv("assets/data/wildfires_survey_all_answers.csv",show_col_types = FALSE))
t_df <- as_tibble(read_csv("assets/data/wildfires_survey_all_answers.csv",show_col_types = FALSE))
t_df
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
?unnest_tokens90
?unnest_tokens()
aq_tokens <- t_df %>%
unnest_tokens(output = word, input = answers, drop = FALSE)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(aq_tokens)
aq_tokens <- t_df %>%
ungroup() %>%
unnest_tokens(output = word, input = answers, drop = FALSE)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(aq_tokens)
aq_tokens1 <- t_df %>%
select(everything()) %>%
mutate(text = unnest_tokens(output = word, input = answers, drop = FALSE)) %>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(text,"[:alpha:]"))%>%
rowwise() %>% mutate(text = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(text, sort = FALSE) %>%
mutate(length = nchar(text))
aq_tokens1 <- t_df %>%
select(everything()) %>%
ungroup() %>%
mutate(text = unnest_tokens(output = word, input = answers, drop = FALSE)) %>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(text,"[:alpha:]"))%>%
rowwise() %>% mutate(text = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(text, sort = FALSE) %>%
mutate(length = nchar(text))
knitr::opts_chunk$set(echo = TRUE)
require(librarian)
librarian::shelf(plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
#Function to adjust table width:
html_table_width <- function(kable_output, width){
width_html <- paste0(paste0('<col width="', width, '">'), collapse = "\n")
sub("<table>", paste0("<table>\n", width_html), kable_output)
}
# Source: https://github.com/rstudio/bookdown/issues/122
t_df <- read_csv("assets/data/wildfires-survey-answers_formatted.csv",show_col_types = FALSE)
t_df1 <- as.data.frame(rbind(t_df[c(1:3),],t_df[c(68:71),], row.names = FALSE))
colnames(t_df1) <- c("ID", "Question type", "Answers")
knitr::kable(head(t_df1),format="html")%>%
html_table_width(c(100,100,500))
knitr::opts_chunk$set(echo = TRUE)
require(librarian)
librarian::shelf(plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
#Function to adjust table width:
html_table_width <- function(kable_output, width){
width_html <- paste0(paste0('<col width="', width, '">'), collapse = "\n")
sub("<table>", paste0("<table>\n", width_html), kable_output)
}
# Source: https://github.com/rstudio/bookdown/issues/122
t_df <- read_csv("assets/data/wildfires-survey-answers_formatted.csv",show_col_types = FALSE)
t_df1 <- as.data.frame(rbind(t_df[c(1:3),],t_df[c(68:71),], row.names = FALSE))
colnames(t_df1) <- c("ID", "Question type", "Answers")
knitr::kable(head(t_df1),format="html")%>%
html_table_width(c(100,100,500))
#For research area questions
ra_dat <- t_df%>%filter(question=="research-a")
#For pressing questions
pq_dat <- t_df%>%filter(question=="pressing-q")
ra_dat%>%
unnest_tokens(output = word, input = answers)%>%
count(word, sort = TRUE)%>%
distinct() %>%
with(wordcloud(word,n, scale = c(3, .07)))
require(librarian)
librarian::shelf(plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr)
t_df <- as_tibble(read_csv("assets/data/wildfires_survey_all_answers.csv",show_col_types = FALSE))
t_df <- as_tibble(read_csv("assets/data/wildfires_survey_all_answers.csv",show_col_types = FALSE))
glimpse(t_df)
summary(t_df)
aq_tokens <- t_df %>%
ungroup() %>%
unnest_tokens(output = word, input = answers, drop = FALSE)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(aq_tokens)
aq_tokens1 <- t_df %>%
select(everything()) %>%
ungroup() %>%
mutate(text = unnest_tokens(output = word, input = answers, drop = FALSE)) %>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(text,"[:alpha:]"))%>%
rowwise() %>% mutate(text = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(text, sort = FALSE) %>%
mutate(length = nchar(text))
head(t_df)
aq_tokens <- t_df %>%
group_by(question) %>%
unnest_tokens(output = word, input = answers, drop = FALSE)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(aq_tokens)
summary(aq_tokens)
aq_tokens <- t_df %>%
group_by(question) %>%
unnest_tokens(output = word, input = answers, drop = FALSE)%>%
ungroup() %>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(aq_tokens)
aq_tokens <- t_df %>%
ungroup() %>%
unnest_tokens(output = word, input = answers, drop = FALSE)%>%
anti_join(stop_words, by = "word")%>%
filter(str_detect(word,"[:alpha:]"))%>%
rowwise() %>% mutate(word = if_else(word!="data",singularize(word),"data")) %>%
distinct() %>%
group_by(question) %>%
count(word, sort = FALSE) %>%
mutate(length = nchar(word))
head(aq_tokens)
summary(aq_tokens)
filter(aq_tokens,n>5)
librarian::shelf(plyr, tidytext, tidyverse,
widyr,igraph, ggraph,
wordcloud, reshape2, graphlayouts,
pluralize, quanteda, qgraph, cowplot, readr,
ggwordcloud)
ggplot(aq_tokens, aes(label = word)) +
geom_text_wordcloud() +
facet_wrap(~question) +
theme_minimal()
p <- ggplot(aq_tokens, aes(label = word)) +
geom_text_wordcloud() +
facet_wrap(~question) +
theme_minimal()
p
summary(aq_tokens)
filter(aq_tokensn>5)
summary(aq_tokens,n>5)
summary(filter(aq_tokens,n>5))
p <- ggplot(filter(aq_tokens,n>5), aes(label = word)) +
geom_text_wordcloud() +
facet_wrap(~question) +
theme_minimal()
p
p <- ggplot(filter(aq_tokens,n>5), aes(label = word, size = n, color = question)) +
geom_text_wordcloud() +
facet_wrap(~question) +
theme_minimal()
p
p <- ggplot(filter(aq_tokens,n>2), aes(label = word, size = n, color = question)) +
geom_text_wordcloud() +
facet_wrap(~question) +
theme_minimal()
p
p <- ggplot(filter(aq_tokens,n>2), aes(label = word, size = n, color = question)) +
geom_text_wordcloud() +
facet_wrap(~question)
p
p <- ggplot(filter(aq_tokens,n>2),
aes(label = word,
size = n,
color = question)) +
geom_text_wordcloud() +
scale_radius(range = c(0, 20),
limits = c(0, NA)) +
facet_wrap(~question)
p
p <- ggplot(filter(aq_tokens,n>2),
aes(label = word,
size = n,
color = question)) +
geom_text_wordcloud(area_corr_power = 1) +
scale_radius(range = c(0, 20),
limits = c(0, NA)) +
facet_wrap(~question)
p
aq_wofire <- filter(aq_tokens,word!= "fire" | word!="wildfire")
aq_wofire <- filter(aq_tokens,word!= "fire")
aq_wofire <- filter(aq_wofire,word!="wildfire")
p <- ggplot(filter(aq_wofire,n>2),
aes(label = word,
size = n,
color = question)) +
geom_text_wordcloud(area_corr_power = 1) +
scale_radius(range = c(0, 20),
limits = c(0, NA)) +
facet_wrap(~question)
p
aq_wofire <- filter(aq_wofire,word!="al")
p <- ggplot(filter(aq_wofire,n>2),
aes(label = word,
size = n,
color = question)) +
geom_text_wordcloud(area_corr_power = 1) +
scale_radius(range = c(0, 20),
limits = c(0, NA)) +
facet_wrap(~question)
p
pq_digrams <- aq_tokens %>%
ungroup() %>%
filter(str_detect(answers,"[:alpha:]"))%>%
unnest_tokens(bigram, answers, token = "ngrams", n = 2) %>%
separate(bigram,c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
group_by(question) %>%
count(word1, word2, sort = TRUE) %>%
mutate(rank = row_number(),
total=sum(n),
t_freq = n/total)
pq_digrams <- aq_tokens %>%
ungroup() %>%
# filter(str_detect(answers,"[:alpha:]"))%>%
unnest_tokens(bigram, answers, token = "ngrams", n = 2) %>%
separate(bigram,c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
group_by(question) %>%
count(word1, word2, sort = TRUE) %>%
mutate(rank = row_number(),
total=sum(n),
t_freq = n/total)
rlang::last_error()
head(t_df)
pq_digrams <- t_df %>%
ungroup() %>%
filter(str_detect(answers,"[:alpha:]"))%>%
unnest_tokens(bigram, answers, token = "ngrams", n = 2) %>%
separate(bigram,c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
group_by(question) %>%
count(word1, word2, sort = TRUE) %>%
mutate(rank = row_number(),
total=sum(n),
t_freq = n/total)
head(pq_digrams)
pq_digrams %>%
group_by(question) %>%
filter(rank < 26) %>%
unite(bigram, word1, word2, sep = " ") %>%
ggplot(aes(t_freq, fct_reorder(bigram, t_freq), fill = t_freq)) +
geom_col(show.legend = FALSE) +
labs(x = "Frequency", y = NULL)+
facet_wrap(~question)
pq_digrams %>%
# group_by(question) %>%
filter(rank < 26) %>%
unite(bigram, word1, word2, sep = " ") %>%
ggplot(aes(t_freq, fct_reorder(bigram, t_freq), fill = t_freq)) +
geom_col(show.legend = FALSE) +
labs(x = "Frequency", y = NULL)+
facet_wrap(~question)
pq_digrams %>%
# group_by(question) %>%
filter(rank < 10) %>%
unite(bigram, word1, word2, sep = " ") %>%
ggplot(aes(t_freq, fct_reorder(bigram, t_freq), fill = t_freq)) +
geom_col(show.legend = FALSE) +
labs(x = "Frequency", y = NULL)+
facet_wrap(~question)
bigram_graph <- pq_digrams %>%
filter(rank < 101) %>%
graph_from_data_frame()
bigram_graph
set.seed(2017)
l <- layout_with_fr(bigram_graph)
e <- get.edgelist(bigram_graph,names=FALSE)
m <- qgraph.layout.fruchtermanreingold(e,vcount=vcount(bigram_graph))
deg <- degree(bigram_graph,mode="all")
fsize <- degree(bigram_graph, mode= "all")
plot(bigram_graph,layout=m, edge.arrow.size =.05,vertex.color = "pink", vertex.size =500,vertex.frame.color="deeppink",vertex.label.color="black", vertex.label.cex=fsize/5,vertex.label.dist=0.8,edge.curve = 0.75,edge.color="skyblue",edge.label.family="Arial", rescale=F, axes = FALSE, ylim = c(-50,90), xlim = c(-55,120), asp =0)
plot(bigram_graph,layout=m, edge.arrow.size =.05,vertex.color = "pink", vertex.size =deg*150,vertex.frame.color="deeppink",vertex.label.color="black", vertex.label.cex=0.55,vertex.label.dist=0.8,edge.curve = 0.75,edge.color="skyblue",edge.label.family="Arial", rescale=F, axes = FALSE, ylim = c(-50,90), xlim = c(-55,120), asp =0)
